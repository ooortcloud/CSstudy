CPU 스케줄링은 `다중 프로그래밍 시스템`을 구현하기 위해서 반드시 생각해야 하는 이슈이다.

CPU 스케줄링은 운영체제가 여러 프로세스나 스레드를 효과적으로 처리하기 위해 CPU를 할당하는 방법입니다. 이 과정에서 CPU는 한 번에 하나의 작업만 수행할 수 있으므로, 스케줄러는 다양한 스케줄링 알고리즘을 통해 어느 프로세스에게 CPU를 할당할지 결정합니다. CPU 스케줄링 알고리즘은 주로 시스템의 응답 시간, 처리율, 공정성 등을 최적화하는 데 중점을 둡니다. 


## 운영체제에서의 큐: 준비 큐, 대기 큐, 실행 큐

운영체제는 다양한 프로세스를 효율적으로 관리하기 위해 큐(Queue)라는 자료구조를 사용합니다. 큐는 먼저 들어온 데이터가 먼저 나가는 선입선출(FIFO) 방식으로 데이터를 관리하는 자료구조입니다. 운영체제에서는 프로세스의 상태에 따라 여러 종류의 큐를 사용하며, 그 중 대표적인 것이 **준비 큐**, **대기 큐**, **실행 큐**입니다.

### 1. 준비 큐 (Ready Queue)

* **정의:** 즉시 실행 가능한 상태에 있는 프로세스들을 모아놓은 목록.
* **역할:**
    * **프로세스 관리:** 시스템 내의 모든 준비된 프로세스를 체계적으로 관리합니다.
    * **스케줄링 기준:** 스케줄러는 준비 큐에 있는 프로세스들을 검토하여 다음에 실행할 프로세스를 선택합니다.
    * **문맥 교환:** 실행 중인 프로세스가 I/O 작업이나 다른 이유로 CPU를 양보하면, 준비 큐에 있는 다른 프로세스가 CPU를 할당받아 실행을 시작합니다.

### 2. 대기 큐 (Wait Queue)

* **정의:** 운영체제에서 프로세스가 특정 자원(CPU, I/O 장치 등)을 사용하기 위해 기다리는 목록.
* **종류:**
    * **I/O 대기 큐:** I/O 작업 완료를 기다리는 프로세스들이 대기하는 큐입니다.
    * **자원 대기 큐:** 특정 자원(메모리, 잠금 등)을 획득하기 위해 대기하는 프로세스들이 있는 큐입니다.
* **역할:**
    * **이벤트 대기:** 프로세스가 필요한 이벤트가 발생할 때까지 대기 상태를 유지합니다.
    * **자원 관리:** 시스템 자원을 효율적으로 관리합니다.

### 3. 실행 큐 (Running Queue)

* **정의:** 현재 CPU를 할당받아 실행 중인 프로세스를 나타내는 큐입니다.
* **역할:**
    * **단일성:** 일반적으로 시스템에는 하나의 실행 큐만 존재하며, 이 큐에는 최대 하나의 프로세스만 존재할 수 있습니다. 
    * **문맥 교환:** 실행 큐에 있는 프로세스가 다른 상태로 전환되면, 대기 큐에서 새로운 프로세스가 선택되어 실행 큐로 이동합니다.

### 큐와 프로세스 상태의 관계

프로세스는 다음과 같은 상태를 거치며, 각 상태에 따라 다른 큐에 위치하게 됩니다.

* **준비 상태:** CPU를 할당받아 실행될 준비가 된 상태. 준비 큐에 위치합니다.
* **실행 상태:** CPU를 할당받아 실행 중인 상태. 실행 큐에 위치합니다.
* **대기 상태:** 어떤 이벤트를 기다리는 상태. 대기 큐에 위치합니다.
* **종료 상태:** 실행이 완료된 상태. 시스템에서 제거됩니다.

### 프로세스의 상태 전환

- **디스패치(dispatch):** 준비 큐의 맨 앞에 있던 프로세스가 CPU를 점유하게 되는 것, 즉 프로세스가 준비 상태에서 실행 상태로 바뀌는 것.
- **블록(block):** 프로세스가 자원 부족, I/O 입출력대기, 인터럽트 등 다른 사유에 의해 실행 상태에서 대기 상태로 전환.
- **활성화(wake-up):** 프로세스가 부족한 자원을 재할당 받았다는 등의 사유로 대기 상태에서 준비 상태로 전환.


### 왜 큐를 사용하는가?

* **프로세스 관리:** 다수의 프로세스를 효율적으로 관리하고 스케줄링할 수 있습니다.
* **자원 할당:** 프로세스에게 필요한 자원을 효율적으로 할당할 수 있습니다.
* **시스템 성능 향상:** 프로세스 상태를 명확하게 관리하여 시스템의 전체적인 성능을 향상시킬 수 있습니다.


## 그 외 배경지식


### 경쟁상태(Race Condition)

`Race Condition(경쟁 상태)`는 여러 프로세스나 스레드가 동시에 공유 자원에 접근하고, 이로 인해 실행 결과가 예측할 수 없게 되는 심각한 상황을 의미합니다. 이는 주로 멀티스레드나 멀티프로세싱 환경에서 발생하며, 적절한 동기화 메커니즘이 없다면 심각한 버그와 시스템 불안정을 초래할 수 있습니다. 


**Race Condition의 발생 원리**

Race Condition은 다음과 같은 상황에서 발생할 수 있습니다:

1. **공유 자원 접근**: 여러 스레드나 프로세스가 동시에 동일한 공유 자원(예: 변수, 메모리 공간, 파일 등)에 접근합니다.
2. **동시 실행**: 이러한 접근이 정확히 같은 시간에 이루어지면, 각각의 작업이 독립적으로 수행되지 않고, 서로의 작업을 간섭할 수 있습니다.
3. **순서의 불확실성**: 어느 스레드가 먼저 실행될지, 어떤 순서로 자원에 접근할지 예측할 수 없으므로, 결과가 실행마다 달라질 수 있습니다.

**예시**

아래의 Python 코드 예제를 통해 Race Condition이 어떻게 발생하는지 살펴보겠습니다.

```python
import threading

counter = 0

def increment_counter():
    global counter
    for _ in range(1000000):
        counter += 1

# 두 개의 스레드가 같은 counter 변수를 수정함
thread1 = threading.Thread(target=increment_counter)
thread2 = threading.Thread(target=increment_counter)

thread1.start()
thread2.start()

thread1.join()
thread2.join()

print(f"Final counter value: {counter}")
```

**설명**

1. **공유 자원**: `counter` 변수는 두 스레드에 의해 동시에 접근되고 수정됩니다.
2. **Race Condition 발생**: `counter += 1` 연산은 여러 단계로 이루어지는데, 이 단계 중간에 다른 스레드가 개입하면 `counter` 값이 정확하게 증가하지 않을 수 있습니다.
3. **불확실한 결과**: 위 코드의 최종 `counter` 값은 2000000이 되어야 하지만, Race Condition이 발생하면 그보다 작은 값이 출력될 수 있습니다.

**Race Condition의 결과**

Race Condition은 매우 위험합니다. 그 결과로 인해 다음과 같은 문제가 발생할 수 있습니다:

- **데이터 손상**: 잘못된 값으로 인해 데이터가 손상되거나, 불일치가 발생할 수 있습니다.
- **비결정성**: 코드의 결과가 실행할 때마다 달라지므로, 디버깅이 매우 어렵습니다.
- **시스템 오류**: 심각한 경우 프로그램 충돌이나 시스템 오류를 유발할 수 있습니다.

**Race Condition 방지 방법**

Race Condition을 방지하려면, 여러 스레드가 동시에 공유 자원에 접근하지 못하도록 해야 합니다. 이를 위해 다양한 **동기화 메커니즘**이 사용됩니다:

- **뮤텍스(Mutex)**: 뮤텍스는 상호 배제를 보장하는 동기화 기법으로, 한 번에 하나의 스레드만 특정 코드 블록을 실행할 수 있게 합니다. 다른 스레드들은 뮤텍스가 해제될 때까지 대기합니다.

  ```python
  import threading

  counter = 0
  counter_lock = threading.Lock()

  def increment_counter():
      global counter
      for _ in range(1000000):
          with counter_lock:  # 뮤텍스를 사용하여 동기화
              counter += 1

  # 두 개의 스레드가 같은 counter 변수를 수정함
  thread1 = threading.Thread(target=increment_counter)
  thread2 = threading.Thread(target=increment_counter)

  thread1.start()
  thread2.start()

  thread1.join()
  thread2.join()

  print(f"Final counter value: {counter}")
  ```

  위 코드에서는 `counter += 1` 연산을 `counter_lock` 뮤텍스로 보호하여, Race Condition을 방지합니다.

- **세마포어(Semaphore)**: 세마포어는 일정 수의 스레드가 자원에 접근할 수 있도록 제한하는 동기화 기법입니다. 예를 들어, 한 번에 최대 N개의 스레드가 특정 자원에 접근할 수 있게 합니다.

- **모니터(Monitor)**: 모니터는 객체 단위로 동기화를 관리하는 방법으로, 객체에 대한 접근을 자동으로 동기화하여 Race Condition을 방지합니다.

- **아토믹 연산(Atomic Operations)**: 일부 프로그래밍 언어에서는 변수의 증감과 같은 단일 연산이 아토믹하게 수행되도록 보장하는 연산을 제공합니다. 이러한 연산은 분할되지 않으며, Race Condition이 발생하지 않습니다.


### I/O 버스트 사이클

I/O 버스트 사이클은 프로세스의 실행 특성을 이해하는 데 매우 중요한 개념입니다. 이를 통해 우리는 운영체제가 프로세스를 어떻게 관리하고, 시스템 자원을 효율적으로 활용하는지 이해할 수 있습니다.

'I/O 버스트 사이클'은 프로세스가 CPU에서 연산을 수행하고 I/O 작업을 기다리는 과정을 반복하는 현상을 의미합니다. 마치 사람이 일을 하다가 잠시 쉬는 것처럼, 프로세스도 CPU에서 계산 작업을 하다가 I/O 작업(예: 파일 읽기, 네트워크 통신)을 요청하고 결과를 기다리는 시간을 갖게 됩니다.

**I/O 버스트 사이클의 구성**

* **CPU 버스트:** 프로세스가 CPU를 할당받아 연산을 수행하는 기간입니다.
* **I/O 버스트:** 프로세스가 I/O 작업을 요청하고 결과를 기다리는 기간입니다.

**프로세스 실행 과정**

1. **CPU 버스트:** 프로세스가 준비 큐에서 선택되어 CPU를 할당받습니다. 할당받은 CPU를 이용하여 연산을 수행합니다.
2. **I/O 요청:** 연산 결과를 저장하거나, 다른 데이터를 읽어오기 위해 I/O 작업을 요청합니다.
3. **대기:** I/O 작업이 완료될 때까지 준비 큐에서 대기합니다. (이 기간 동안 다른 프로세스가 CPU를 사용합니다.)
4. **I/O 완료:** I/O 작업이 완료되면 다시 준비 큐로 돌아와 CPU를 할당받기 위해 대기합니다.
5. **반복:** 위 과정을 반복합니다.

**I/O 버스트 사이클의 중요성**

* **CPU 스케줄링:** I/O 버스트 사이클의 특성을 고려하여 CPU를 효율적으로 할당하는 스케줄링 알고리즘이 필요합니다. (예: SJF, SRTF, RR 등)
* **메모리 관리:** 프로세스가 I/O 작업을 수행하는 동안 메모리를 효율적으로 관리해야 합니다.
* **시스템 성능:** I/O 버스트 사이클을 최적화하면 시스템의 전체적인 성능을 향상시킬 수 있습니다.

**I/O 버스트 사이클 예시**

* **웹 서버:** 웹 서버 프로세스는 클라이언트의 요청을 처리하기 위해 CPU 버스트를 수행하고, 파일 시스템에서 HTML 파일을 읽어오거나 데이터베이스에 접근하는 등의 I/O 작업을 수행합니다.
* **컴파일러:** 컴파일러 프로세스는 소스 코드를 분석하고 기계어 코드로 변환하는 CPU 버스트를 수행하고, 파일 시스템에서 소스 코드를 읽어오거나 목적 파일을 쓰는 I/O 작업을 수행합니다.

### 교착상태(Deadlock)

### 기아상태(Starvation)
기아 상태란 운영체제에서 프로세스가 필요한 자원을 무한정 기다리는 상태를 말합니다. 마치 밥을 먹기 위해 줄을 서 있지만, 자꾸 다른 사람에게 먼저 양보하다가 결국 밥을 먹지 못하는 상황과 비슷합니다. 기아 상태는 교착 상태와는 달리 특정 프로세스에게만 영향을 미치며, 다른 프로세스는 계속해서 자원을 사용할 수 있습니다. 기아 상태가 발생하면 해당 프로세스는 영원히 자원을 얻지 못하는 상태가 됩니다. 이를 방지하기 위해서는 공정한 자원 할당 및 우선순위 부여와 같은 방법을 사용하여 모든 프로세스가 적절한 기회를 가지도록 해야 합니다.

기아상태를 해결하기 위해 다음과 같은 방법을 사용해볼 수 있다.
- **공정한 스케줄링 알고리즘 사용**: 모든 프로세스에게 공평하게 CPU 시간을 할당하는 스케줄링 알고리즘을 사용합니다. (예: 라운드 로빈 스케줄링)
- **우선순위 조정**: 오랫동안 대기한 프로세스의 우선순위를 높여줍니다.
- **자원 할당 전략 개선**: 자원 할당 알고리즘을 개선하여 모든 프로세스가 공평하게 자원을 얻을 수 있도록 합니다.
- **교착 상태 방지**: 교착 상태 발생 조건을 충족시키지 않도록 시스템을 설계합니다.

### 노화기법(Aging)
기아현상을 해결하기 위해 도입한 솔루션.

### PCB(Process Control Block)
PCB(Process Control Block)는 운영체제가 각 프로세스에 대한 정보를 저장하는 데이터 구조입니다. 마치 여권이 한 사람의 신원과 여행 정보를 담고 있는 것처럼, PCB는 운영체제가 하나의 프로세스를 식별하고 관리하는 데 필요한 모든 정보를 담고 있습니다.

PCB는 운영체제가 다수의 프로세스를 효율적으로 관리하는 데 필수적인 데이터 구조입니다. PCB가 없다면 운영체제는 각 프로세스의 상태를 추적하고 관리할 수 없으며, 따라서 다중 프로그래밍 시스템을 구현할 수 없습니다.

[더 자세한 정보](./세부%20개념/프로세스%20제어%20블록.md)



## 스케줄링 알고리즘
### CPU 스켸줄링이란
CPU 스케줄링은 준비큐에 있는 여러 개의 프로세스가 동시에 실행을 요청할 때, 어떤 프로세스에게 먼저 CPU를 할당할지를 결정하는 작업을 말합니다. 마치 여러 사람이 한정된 자원인 CPU를 사용하려고 할 때, 누구에게 먼저 자원을 줄지를 정하는 것과 같습니다.

### CPU 스케줄링의 결정
CPU 스케줄링의 결정은 다음의 네 가지 상황에서 발생할 수 있다.

- 한 프로세스가 실행 상태에서 대기 상태로 전환될 때 (I/O 발생)
- 프로세스가 실행 상태에서 준비 완료 상태로 전환될 때 (인터럽트 발생)
- 프로세스가 대기 상태에서 준비 완료 상태로 전환될 때 (I/O 종료)
- 프로세스가 종료할 때

### 스케줄링 기준
여러 CPU 스케줄링 알고리즘 사이에서 하나를 선택하기 위한 CPU 스케줄링 비교 기준은 다음과 같다.

- CPU 이용률(Utilization): 어느 기간 동안 또는 특정 SNAPSHOT에서의 CPU의 이용률을 말한다.
- 처리량(Throughput): 단위 시간당 완료된 프로세스의 개수로써 나타낼 수 있다.
- 총처리 시간(Turnaround Time): 프로세스의 제출 시간과 완료 시간의 간격을 총처리 시간이라고 한다.
- 대기 시간(Waiting Time): 대기 시간은 프로세스가 준비 큐에서 대기하면서 보낸 시간의 합이다.
- 응답 시간(Response Time): 하나의 Request를 제출한 후 첫 번째 Response가 나올 때까지의 시간이다.

### 1. 비선점형 스케줄링(Non-Preemptive Scheduling)
비선점형 스케줄링에서는 프로세스가 CPU를 할당받으면 작업이 완료될 때까지 CPU를 독점적으로 사용하며, 운영체제가 강제로 CPU를 빼앗을 수 없다. 다른 프로세스는 현재 프로세스가 종료되거나, 입출력 작업을 위해 자발적으로 CPU를 포기할 때까지 대기합니다.

#### **종류**
- **FCFS(First-Come, First-Served, 선입선출):**
  
  FCFS 스케줄링은 선착순 스케줄링이라고도 불리며, 가장 간단한 스케줄링 알고리즘 중 하나입니다. 먼저 요청한 프로세스가 먼저 CPU를 할당받는 방식으로, 마치 은행 창구에 먼저 온 사람이 먼저 업무를 보는 것과 같습니다.
  - 가장 먼저 도착한 프로세스가 먼저 CPU를 할당받습니다.
  - 구현이 간단하지만, CPU를 많이 사용하는 프로세스가 먼저 도착하면 다른 프로세스들이 오래 대기하게 되는 *Convoy Effect*가 발생할 수 있습니다.
  
  <img src="../이미지%20폴더/FCFS 문제.png" width="25%" height="25%" />

  |최소 평균 반환 시간|최대 평균 반환 시간|
  |---|---|
  | (6 + (6 + 9) + (6 + 9 + 12)) / 3 = 16 | (12 + (12 + 9) + (12 + 9 + 6)) / 3 = 20  |

- **SJF(Shortest Job First, 최단작업우선):**
 
  SJF 스케줄링은 최단 작업 우선 스케줄링이라고도 불리며, 준비 큐에 있는 프로세스 중 실행 시간이 가장 짧은 프로세스에게 먼저 CPU를 할당하는 비선점형 스케줄링 알고리즘입니다. 즉, 짧은 작업을 먼저 처리하여 평균 대기 시간을 최소화하는 것을 목표로 합니다.

  - CPU 사용 시간이 가장 짧은 프로세스에게 우선적으로 CPU를 할당합니다.
  - 평균 대기 시간을 최소화할 수 있지만, 모든 프로세스의 실행 시간을 미리 알아야 한다는 단점이 있습니다.
  - 실행 시간이 긴 프로세스의 경우 기아 상태에 빠질 수 있다.

  <img src="../이미지%20폴더/SJF 문제.png" width="12.5%" height="12.5%" />

  |평균 반환 시간|평균 대기 시간|
  |---|---|
  | (3 + (3 + 6) + (3 + 6 + 7) + (3 + 6 + 7 + 8)) / 4 = 13 | (0 + (0 + 3) + (0 + 3 + 6) + (0 + 3 + 6 + 7)) / 4 = 7  |

- **HRN(Highest Response-ratio Next):**
  
  대기 시간과 서비스 시간의 비율을 계산하여, 가장 높은 비율을 가진 프로세스에게 우선적으로 CPU를 할당합니다. SJF보다 공정성을 고려한 방식입니다.

  $우선순위 계산식 = 1 + (대기시간 / 실행시간)$
  
  위 값이 클수록 우선순위가 높아진다. 실행시간 대비 대기시간이 길수록 우선권을 더 높게 쳐준다는 뜻이다.

  <img src="../이미지%20폴더/HRN 문제.png" width="20%" height="20%" />

  |프로세스|우선순위 계산값|우선순위|
  |---|---|---|
  | A | 1 + (8/2) = 5  | 1 |
  | B | 1 + (10/6) = 2.67  | 4 |
  | C | 1 + (15/7) = 3.14  | 3 |
  | D | 1 + (20/8) = 3.5  | 2 |

- **Priority Scheduling:**
  
  우선순위 스케줄링은 각 프로세스에 우선순위를 부여하고, 우선순위가 높은 프로세스에게 먼저 CPU를 할당하는 스케줄링 알고리즘입니다. 마치 중요한 업무를 먼저 처리하는 것과 같이, 시스템에 중요한 프로세스에게 더 많은 기회를 제공하여 시스템의 효율성을 높이고자 하는 목적을 가지고 있습니다.
  - 각 프로세스에 우선순위를 부여하고, 우선순위가 높은 프로세스가 먼저 CPU를 할당받습니다.
  - 우선순위가 같은 프로세스가 여러 개일 경우, FCFS (First Come First Served) 방식이나 다른 스케줄링 알고리즘을 적용하여 처리합니다.
  - 시스템에 중요한 프로세스에게 우선적으로 CPU를 할당하여 시스템의 응답성을 높일 수 있습니다. 하지만 우선순위가 낮은 프로세스가 오랫동안 CPU를 할당받지 못하는 *Starvation(기아)* 문제가 발생할 수 있습니다. 이를 방지하기 위해 우선순위를 동적으로 조정하는 *Aging(노화)* 기법을 사용할 수 있습니다. (오랫동안 시스템에서 대기하는 프로세스들의 우선순위를 점진적으로 증가시킴)



### 2. 선점형 스케줄링(Preemptive Scheduling)
선점형 스케줄링에서는 현재 실행 중인 프로세스가 CPU를 사용 중이라도, 더 높은 우선순위를 가진 프로세스가 도착하면 CPU를 뺏을 수 있습니다. 이 방식은 시스템 응답성을 높이는 데 유리합니다.

#### **종류**
- **Round Robin (RR):**
  
  라운드 로빈 스케줄링은 시분할 시스템에서 주로 사용되는 선점형 스케줄링 알고리즘 중 하나입니다. 마치 원형 테이블에서 순서대로 돌아가며 빵을 나눠 먹는 것처럼, 준비 큐에 있는 프로세스들에게 동일한 시간 단위(Time Quantum, Time Slice)로 CPU를 할당하는 방식입니다. CPU 스케줄러는 준비 큐를 돌면서 한 번에 한 프로세스에 한 번의 시간 할당량 동안 CPU를 할당한다.
  - 각 프로세스는 일정한 시간 단위를 받습니다. 할당 시간이 지나면, 현재 실행 중인 프로세스를 강제로 중단하고 다음 프로세스에게 CPU를 할당한다.
  - 공정성이 높고, 모든 프로세스가 주기적으로 CPU를 사용할 수 있어 시스템 응답성을 보장합니다. 하지만 시간 단위가 너무 짧으면 컨텍스트 스위칭 오버헤드가 커질 수 있습니다.

- **SRT (Shortest Remaining Time):**
  
  SRT (Shortest Remaining Time) 스케줄링은 최소 잔여 시간 스케줄링이라고도 불리며, 현재 실행 중인 프로세스를 중단시키고 새로 들어온 프로세스의 처리를 시작하는 선점형 스케줄링 알고리즘입니다. 즉, 남은 실행 시간이 가장 짧은 프로세스에게 우선적으로 CPU를 할당하는 방식입니다. SJF의 선점형 버전이다.
  - 현재 남아 있는 실행 시간이 가장 짧은 프로세스가 우선적으로 CPU를 할당받습니다. 새로운 프로세스가 도착할 때마다 남은 시간을 기준으로 CPU를 재할당할지 결정합니다.
  - 평균 대기 시간을 줄일 수 있지만, 프로세스의 잦은 선점으로 인한 컨텍스트 스위칭 오버헤드가 발생할 수 있습니다.

  <img src="../이미지%20폴더/SRT 문제.png" width="20%" height="20%" />

  ![SRT문제](../이미지%20폴더/SRT%20답안.png)

  |프로세스|도착 시간|실행 시간|반환 시간|평균 반환 시간|
  |------|---|---|---|---|
  |P1|0|8|17 - 0 = 17|28 / 4 = 7|
  |P2|2|4|7 - 2 = 5|28 / 4 = 7|
  |P3|4|1| 5 - 4 = 1|28 / 4 = 7|
  |P4|6|4| 11 - 6 = 5 |28 / 4 = 7|

- **Multi-Level Queue(MLQ):**
  
  다단계 큐 스케줄링은 우선순위 스케줄링과 라운드 로빈 스케줄링이 결합한 스케줄링 알고리즘이다. 준비 큐를 여러 개로 나누어 각 큐에 우선순위를 부여하고, 각 큐에 대해 다른 스케줄링 알고리즘을 적용하는 방식입니다. 이를 통해 다양한 종류의 프로세스를 효율적으로 관리하고, 시스템의 성능을 향상시킬 수 있습니다.
  - 프로세스를 여러 큐로 나누고, 각 큐에 대해 서로 다른 스케줄링 알고리즘을 적용합니다. 예를 들어, 실시간 프로세스는 높은 우선순위 큐에서 처리하고, 일반 프로세스는 낮은 우선순위 큐에서 처리합니다. 각 큐에 대해 라운드 로빈, SJF 등 다양한 스케줄링 알고리즘을 적용할 수 있습니다.
  - 각 큐에 우선순위를 부여하여 높은 우선순위의 큐에 있는 프로세스가 먼저 실행됩니다.
  - 프로세스의 특성(I/O 바운드, CPU 바운드 등)에 따라 큐를 분류하여 적합한 스케줄링을 적용할 수 있습니다.
  - 특정 큐에 속한 프로세스가 다른 큐로 이동할 수는 없습니다.

  <img src="../이미지%20폴더/MLQ.png" width="50%" height="50%" />

- **Multi-Level Feedback Queue(MLFQ):**
  
  다단계 피드백 큐 스케줄링은 여러 개의 준비 큐를 사용하여 프로세스를 관리하는 스케줄링 기법입니다. 이는 기본적인 다단계 큐 스케줄링에서 한 단계 발전된 형태로, 프로세스가 큐 사이를 이동할 수 있다는 특징을 가지고 있습니다. 이 알고리즘은 특정 시스템에 부합하도록 구성이 가능함으로 현대 사용되는 CPU 스케줄링 알고리즘 중 가장 일반적인 CPU 스케줄링 알고리즘이다.
  - Multilevel Queue Scheduling과 유사하지만, 프로세스가 다른 큐로 이동할 수 있습니다. 주로 긴 작업은 우선순위를 낮추고, 짧은 작업은 높은 우선순위를 부여하여 시스템 성능을 최적화합니다.
  - 각 큐에서 프로세스는 정해진 시간 할당량만큼 CPU를 사용할 수 있습니다.
  - 새로 생성된 프로세스는 가장 높은 우선순위의 큐에 할당됩니다.
  - 할당된 시간 안에 작업을 완료하지 못하면 낮은 우선순위의 큐로 이동합니다.
  - 특정 조건(예: 일정 시간 동안 대기)을 만족하면 낮은 우선순위의 큐에 있던 프로세스가 높은 우선순위의 큐로 이동할 수 있습니다.
  - I/O 작업을 많이 수행하는 프로세스는 낮은 우선순위의 큐로 이동하여 CPU를 자주 차지하지 않도록 합니다.
  - 일정 시간마다 모든 프로세스들을 최상위 큐로 끌어 올려서 최하위 큐에 있는 프로세스들의 기아 상태를 예방한다.

  <img src="../이미지%20폴더/MLFQ.png" width="50%" height="50%" />

### 3. 비교 및 활용

- **선점형 vs 비선점형**: 
  - 선점형 스케줄링은 응답성을 높일 수 있지만, 컨텍스트 스위칭 오버헤드가 큽니다. 
  - 비선점형 스케줄링은 컨텍스트 스위칭 오버헤드가 없으나, 특정 프로세스가 너무 오랫동안 CPU를 점유할 수 있습니다.

- **응답성 vs 처리율**:
  - Round Robin은 응답성을 중요시하는 시스템에 적합합니다.
  - SJF나 SRTF는 처리율을 최적화하는 데 유리합니다.

- **우선순위 기반 스케줄링**:
  - 시스템에서 처리해야 할 작업의 중요도에 따라 프로세스 우선순위를 설정하고 싶을 때 적합합니다.
